{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLMI3JfoEcl1"
      },
      "source": [
        "*Pendant les 3 premières séances de TP, nous allons mettre en pratique certaines des méthodes présentées en cours pour détecter des objets dans une image.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxZ6cVouz9Lp"
      },
      "source": [
        "# Localisation et classification d'objet\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd4SVfDxz5aw"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Dans cette partie, nous allons nous concentrer sur le problème de la localisation d'un seul objet par classe. La base de données a été épurée pour se concentrer uniquement sur ce cas.\n",
        "\n",
        "En localisation et détection, on cherche à déterminer la position d'un objet, ainsi que sa classe, sous la forme d'une boîte englobante de largeur $b_w$ et hauteur $b_h$, et dont le centre a pour coordonnées le point $(b_x, b_y)$.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1_jHHv6ZDe-3Xz25jIZ6o177laBEfmMRR\" style=\"width:500;height:300px;\"></center>\n",
        "<caption><center> Figure 1: Modèle de boîte englobante utilisé pour la localisation </center></caption>\n",
        "\n",
        "Le problème de localisation considère qu'un seul objet est présent sur l'image, alors que le problème de détection cherche à déterminer l'ensemble des objets présents sur l'image.\n",
        "\n",
        "\n",
        "\n",
        "Pour commencer, récupérez les images de la base de données :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ZjveWpbuNeV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'mangeoires_loc' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/axelcarlier/mangeoires_loc.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF6aRZLE2-Yl"
      },
      "source": [
        "La base de données consiste en des photographies prises par une caméra reliée à une Raspberry Pi, cachée dans une mangeoire. Plusieurs mangeoires sont disséminées dans la nature en Occitanie, et l'objectif de [ce projet](https://econect.cnrs.fr/) est la reconnaissance des espèces et le comptage des individus qui viennent se poser devant le caméra, afin de suivre l'évolution des populations d'oiseaux et ainsi monitorer la biodiversité.\n",
        "\n",
        "La base de données qui vous est fournie regroupe 11 espèces d'animaux, majoritairement des oiseaux, désignés par un code :\n",
        "\n",
        "1. Mésange charbonnière (**MESCHA**)\n",
        "2. Verdier d'Europe (**VEREUR**)\n",
        "3. Écureuil roux (**ECUROU**)\n",
        "4. Pie bavarde (**PIEBAV**)\n",
        "5. Sittelle torchepot (**SITTOR**)\n",
        "6. Pinson des arbres (**PINARB**)\n",
        "7. Mésange noire (**MESNOI**)\n",
        "8. Mésange nonnette (**MESNON**)\n",
        "9. Mésange bleue (**MESBLE**)\n",
        "10. Rouge-gorge (**ROUGOR**)\n",
        "11. Accenteur mouchet (**ACCMOU**)\n",
        "\n",
        "\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1Eit86N4D0Ea7ai1rBa0o-GmTwckhP9i0\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=1lC7WL93UqDT_KV2m21yx99N5dkf98nCY\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=10tzJORcSrSckDWmBDBtc8FUirxdbRxri\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=1IHZp_B6bc8bADtAReRHhcyOjDQZAXDBQ\" width=200></center>\n",
        "<caption><center> Figure 2: Exemples d'images de la base de données </center></caption>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SBA3fa8RSDpt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n",
            "2025-03-05 14:11:59.576099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRm5oT-_Qsw"
      },
      "source": [
        "## Préparation des données\n",
        "\n",
        "Le code ci-dessous permet de charger les données et les formater pour la classification. Prenez le temps de regarder un peu le format des labels $y$.\n",
        "Notez que les images sont rendues carrées lors du chargement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q54zSuMvGM-5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['MESCHA', 'VEREUR', 'ECUROU', 'PIEBAV', 'SITTOR', 'PINARB', 'MESNOI', 'MESNON', 'MESBLE', 'ROUGOR', 'ACCMOU']\n"
          ]
        }
      ],
      "source": [
        "# Lecture du CSV contenant les informations relatives à la base de données\n",
        "dataset = []\n",
        "with open('mangeoires_loc/bd_mangeoires_equilibre.csv', newline='') as csvfile:\n",
        "\tfilereader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "\tfor row in filereader:\n",
        "\t\tdata = row[0].split(',')\n",
        "\t\tif data[0] != 'Data':\n",
        "\t\t\tbox = [float(data[5]), float(data[6]), float(data[7]), float(data[8])]\n",
        "\t\t\tnew_entry = {'type': data[0], 'specie': data[1], 'path': data[2], 'shape': [float(data[3]), float(data[4])], 'box': box}\n",
        "\t\t\tdataset.append(new_entry)\n",
        "\n",
        "# Nombre de classes de la base de données et intitulé des classes\n",
        "class_labels = list(dict.fromkeys([item['specie'] for item in dataset]))\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "# Extraction des données d'apprentissage et de test\n",
        "dataset_train = [item for item in dataset if item['type']=='TRAIN']\n",
        "dataset_test = [item for item in dataset if item['type']=='TEST']\n",
        "\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JPzqdJBVJLWJ"
      },
      "outputs": [],
      "source": [
        "def build_localization_tensors(image_size, dataset, num_classes):\n",
        "  # Préparation des structures de données pour x et y\n",
        "  x = np.zeros((len(dataset), image_size, image_size, 3))\n",
        "  y = np.empty((len(dataset), num_classes + 5)) # 1 + 4 + num_classes : présence / boîte englobante / classes\n",
        "\n",
        "  # Compteur de parcours du dataset\n",
        "  i = 0\n",
        "\n",
        "  for item in dataset:\n",
        "    # Lecture de l'image\n",
        "    img = Image.open('mangeoires_loc/' + item['path'])\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((image_size,image_size), Image.Resampling.LANCZOS)\n",
        "    # Remplissage de la variable x\n",
        "    x[i] = np.asarray(img)\n",
        "\n",
        "    y[i, 0] = 1 # Un objet est toujours présent !\n",
        "\n",
        "    # Coordonnées de boîte englobante\n",
        "    img_shape = item['shape']\n",
        "    box = item['box']\n",
        "    bx = (box[0] + (box[2] - box[0])/2)/img_shape[0]\n",
        "    by = (box[1] + (box[3] - box[1])/2)/img_shape[1]\n",
        "    bw = (box[2] - box[0])/img_shape[0]\n",
        "    bh = (box[3] - box[1])/img_shape[1]\n",
        "    y[i, 1] = bx\n",
        "    y[i, 2] = by\n",
        "    y[i, 3] = bw\n",
        "    y[i, 4] = bh\n",
        "\n",
        "    # Probabilités de classe, sous la forme d'une one-hot vector\n",
        "    label = class_labels.index(item['specie'])\n",
        "    classes_probabilities = keras.utils.to_categorical(label, num_classes=num_classes)\n",
        "    y[i, 5:] = classes_probabilities\n",
        "\n",
        "    i = i+1\n",
        "\n",
        "  return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnlljZWc_i1L"
      },
      "source": [
        "Séparation des données d'entraînement pour extraire un ensemble de validation, et pré-traitement des données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJLRiuFX_VPL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Pour la suite du TP on considèrera des images de taille 64x64x3\n",
        "# Augmenter cette valeur donnerait de meilleurs résultats mais nécessiterait des calculs plus long.\n",
        "IMAGE_SIZE = 64\n",
        "\n",
        "# Lecture des données d'entraînement et de test\n",
        "x, y = build_localization_tensors(IMAGE_SIZE, dataset_train, num_classes)\n",
        "x_test, y_test = build_localization_tensors(IMAGE_SIZE, dataset_test, num_classes)\n",
        "\n",
        "#Extraction d'un ensemble de validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.10, random_state=42)\n",
        "\n",
        "# Pour améliorer l'entraînement, on peut centrer-réduire les coordonnées des bounding boxes...\n",
        "y_std = np.std(y_train, axis=0)\n",
        "y_mean = np.mean(y_train, axis=0)\n",
        "y_train[...,1:5] = (y_train[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "y_val[...,1:5] = (y_val[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "y_test[...,1:5] = (y_test[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "\n",
        "# ... et normaliser les valeurs de couleur\n",
        "x_train = x_train/255\n",
        "x_val = x_val/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4wQYq3AKnA"
      },
      "source": [
        "## Fonctions utiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6NBpMtaM-C0"
      },
      "source": [
        "Une fonction de calcul de l'intersection sur union, qui nous sera utile pour les métriques d'évaluation de nos méthodes :\n",
        "\n",
        "$$ IoU (R_1, R_2) = \\frac{\\mathcal{A} (R_1 \\cap R_2)}{\\mathcal{A} (R_1 \\cup R_2)} = \\frac{\\mathcal{A} (R_1 \\cap R_2)}{\\mathcal{A} (R_1) + \\mathcal{A} (R_2) -  \\mathcal{A} (R_1 \\cap R_2)} $$\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1BQx2kDOCltZ_5gcnKVWTVUVNmGk-7qBC\" width=500>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr-O1XuwLoL3"
      },
      "outputs": [],
      "source": [
        "### A COMPLETER\n",
        "def intersection_sur_union(box1, box2):\n",
        "  \"\"\"\n",
        "  Calcul de l'intersection sur union entre deux rectangles box1 et box2\n",
        "\n",
        "  Arguments:\n",
        "  box1, box2 -- les coordonnées des deux rectangles, chacun sous la forme [cx, cy, w, h]\n",
        "                où (cx, cy) désigne les coordonnées du centre du rectangle,\n",
        "                w sa largeur et h sa hauteur\n",
        "\n",
        "  Retourne :\n",
        "  iou -- la valeur d'intersection sur union entre les deux rectangles\n",
        "  \"\"\"\n",
        "\n",
        "  def union(box1,box2) :\n",
        "    if \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmOmOert8bEm"
      },
      "source": [
        "Exécutez le bloc suivant pour vérifier votre implémentation :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KOhbBB67hx3"
      },
      "outputs": [],
      "source": [
        "print(intersection_sur_union([2.5, 2, 1, 4], [2, 3, 4, 2]))  # Résultat attendu : 0.2\n",
        "print(intersection_sur_union([2.5, 2, 1, 4], [5, 3, 4, 2]))  # Résultat attendu : 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLpMJGi3QC9i"
      },
      "source": [
        "On va maintenant calculer les différentes métriques :\n",
        "\n",
        "$$ P = \\frac{TP}{TP + FP} $$\n",
        "\n",
        "$$ R = \\frac{TP}{TP + FN} $$\n",
        "\n",
        "$$ F1 = \\frac{2 * P * R}{P + R} $$\n",
        "\n",
        "où $TP$ désigne le nombre de vrais positifs, $FP$ le nombre de faux positifs, $FN$ le nombre de faux négatifs, $P$ la précision, $R$ le rappel et $F1$ le F1-score.\n",
        "\n",
        "On considère souvent qu'une détection est correcte si la classification est valide et que l'intersection sur union entre vérité terrain et prédiction est supérieure à 0.5 (on utilisera un seuil modifiable *iou_thres*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e_aIvjXLq32"
      },
      "outputs": [],
      "source": [
        "# On considère souvent qu'une détection est correcte si la classification est valide et que\n",
        "# l'intersection sur union entre vérité terrain et prédiction est supérieure à 0.5\n",
        "def global_accuracy(y_true, y_pred, iou_thres=0.5):\n",
        "  \"\"\"\n",
        "  Calcul, pour chaque classe de la précision, du rappel et du F1-score ainsi\n",
        "  que du pourcentage global de bonnes détections.\n",
        "\n",
        "  Arguments:\n",
        "  y_true -- les labels de la vérité terrain, de dimension (M, 1+4+N) où M désigne\n",
        "          le nombre d'éléments du dataset et N le nombre de classes (11 dans notre cas)\n",
        "  y_pred -- les labels prédits par un modèle, de dimension (M, 1+4+N)\n",
        "  iou_thres -- seuil d'intersection sur union entre une boîte \"vérité-terrain\" et\n",
        "              une boite prédite au-dessus duquel on considère que la prédiction est correcte\n",
        "\n",
        "  Retourne :\n",
        "  class_res -- liste de longueur N contenant des dictionnaires sous la forme\n",
        "            {\"Précision\": p, \"Rappel\": r, \"F-score\": f} résumant les métriques\n",
        "            précision, rappel et F1-score pour chacune des classes.\n",
        "  accuracy -- pourcentage global de bonnes détections\n",
        "  \"\"\"\n",
        "  # Initialisation des métriques : nombre de vrais positifs (TP), faux positifs (FP)\n",
        "  # et faux négatifs (FN) pour chaque classe\n",
        "  class_metrics = []\n",
        "  for i in range(num_classes):\n",
        "    class_metrics.append({'TP': 0, 'FP': 0, 'FN': 0})\n",
        "\n",
        "  # Nombres de détections correctes et de détections incorrectes\n",
        "  total_correct_detections = 0\n",
        "  toal_incorrect_detections = 0\n",
        "  for i in range(y_true.shape[0]):\n",
        "    # Labels vérité-terrain et prédits\n",
        "    groundtruth_label = np.argmax(y_true[i,5:])\n",
        "    predicted_label = np.argmax(y_pred[i,5:])\n",
        "\n",
        "    # Coordonnées de boîtes englobantes réelles et prédites\n",
        "    bx_true = (y_true[i,1]*y_std[1] + y_mean[1])\n",
        "    by_true = (y_true[i,2]*y_std[2] + y_mean[2])\n",
        "    bw_true = (y_true[i,3]*y_std[3] + y_mean[3])\n",
        "    bh_true = (y_true[i,4]*y_std[4] + y_mean[4])\n",
        "    bx_pred = (y_pred[i,1]*y_std[1] + y_mean[1])\n",
        "    by_pred = (y_pred[i,2]*y_std[2] + y_mean[2])\n",
        "    bw_pred = (y_pred[i,3]*y_std[3] + y_mean[3])\n",
        "    bh_pred = (y_pred[i,4]*y_std[4] + y_mean[4])\n",
        "\n",
        "    # Calcul de l'intersection sur union\n",
        "    iou = intersection_sur_union([bx_true, by_true, bw_true, bh_true], [bx_pred, by_pred, bw_pred, bh_pred])\n",
        "\n",
        "    ### A COMPLETER\n",
        "    # Si la détection est correcte :\n",
        "    if groundtruth_label == predicted_label and iou > iou_thres:\n",
        "      # Mettre à jour le nombre de Vrais Positifs pour la classe vérité terrain :\n",
        "      # class_metrics[class_id]['TP']=...\n",
        "      ...\n",
        "    else:\n",
        "      # Mettre à jour le nombre de Faux Positifs et/ou Faux Négatifs pour les\n",
        "      # classes concernées\n",
        "      ...\n",
        "\n",
        "  class_res = []\n",
        "  for i in range(num_classes):\n",
        "    # Pour chaque classe, on veut calculer Précision, Rappel et F1-Score à partir\n",
        "    # des TP, FP et FN calculés sur le bloc précédent\n",
        "    P = ...\n",
        "    R = ...\n",
        "    F_score = ...\n",
        "    class_res.append({'Precision': P, 'Rappel': R, 'F-score': F_score})\n",
        "\n",
        "  accuracy = ...\n",
        "  ### FIN\n",
        "  return class_res, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSU6oPWpkVfg"
      },
      "outputs": [],
      "source": [
        "num_class_test = 3\n",
        "class_labels_test = ['Classe 1', 'Classe 2', 'Classe 3']\n",
        "y_true_test = np.ones((num_class_test,8))\n",
        "y_true_test[0,:2] = [0.5, 0.5]\n",
        "y_true_test[0, 5:] = [1, 0, 0]\n",
        "y_true_test[1,:2] = [0.5, 0.5]\n",
        "y_true_test[1, 5:] = [0, 1, 0]\n",
        "y_true_test[2,:2] = [0.5, 0.5]\n",
        "y_true_test[2, 5:] = [0, 0, 1]\n",
        "y_pred_test = np.ones((num_class_test,8))\n",
        "y_pred_test[0,:2] = [0.6, 0.6]\n",
        "y_pred_test[0, 5:] = [1, 0, 0]\n",
        "y_pred_test[1,:2] = [2.5, 2.5]\n",
        "y_pred_test[1, 5:] = [0, 0, 1]\n",
        "y_pred_test[2,:2] = [0.6, 0.6]\n",
        "y_pred_test[2, 5:] = [0, 0, 1]\n",
        "\n",
        "class_res_test, acc_test = global_accuracy(y_true_test, y_pred_test)\n",
        "\n",
        "print(f\"La précision globale est de {acc_test:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"|  Classe  | Précision | Rappel | F1-score |\")\n",
        "print(\"--------------------------------------------\")\n",
        "for i in range(num_class_test):\n",
        "  print(f\"| {class_labels_test[i]:9s}|   {class_res_test[i]['Precision']:.2f}    |  {class_res_test[i]['Rappel']:.2f}  |   {class_res_test[i]['F-score']:.2f}   |\")\n",
        "  print(\"--------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fhT7tYlkW_I"
      },
      "source": [
        "**Affichage attendu :**\n",
        "```\n",
        "La précision globale est de 66.7%\n",
        "\n",
        "--------------------------------------------\n",
        "|  Classe  | Précision | Rappel | F1-score |\n",
        "--------------------------------------------\n",
        "| Classe 1 |   1.00    |  1.00  |   1.00   |\n",
        "--------------------------------------------\n",
        "| Classe 2 |   0.00    |  0.00  |   0.00   |\n",
        "--------------------------------------------\n",
        "| Classe 3 |   0.50    |  1.00  |   0.67   |\n",
        "--------------------------------------------\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMntCEgkANMg"
      },
      "source": [
        "La fonction ci-dessous permet de calculer l'intersection sur union  sur des tenseurs (et non des tableaux numpy), elle sera donc utilisable comme métrique pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVk9cB1WAMUK"
      },
      "outputs": [],
      "source": [
        "def compute_iou(y_true, y_pred):\n",
        "  ### \"Dénormalisation\" des coordonnées des boîtes englobantes\n",
        "  pred_box_xy = y_pred[..., 0:2]* y_std[0:2] + y_mean[0:2]\n",
        "  true_box_xy = y_true[..., 0:2]* y_std[0:2] + y_mean[0:2]\n",
        "\n",
        "  ### \"Dénormalisation\" des largeur et hauteur des boîtes englobantes\n",
        "  pred_box_wh = y_pred[..., 2:4] * y_std[2:4] + y_mean[2:4]\n",
        "  true_box_wh = y_true[..., 2:4] * y_std[2:4] + y_mean[2:4]\n",
        "\n",
        "  # Calcul des coordonnées minimales et maximales des boiptes englobantes réelles\n",
        "  true_wh_half = true_box_wh / 2.\n",
        "  true_mins    = true_box_xy - true_wh_half\n",
        "  true_maxes   = true_box_xy + true_wh_half\n",
        "\n",
        "  # Calcul des coordonnées minimales et maximales des boiptes englobantes prédites\n",
        "  pred_wh_half = pred_box_wh / 2.\n",
        "  pred_mins    = pred_box_xy - pred_wh_half\n",
        "  pred_maxes   = pred_box_xy + pred_wh_half\n",
        "\n",
        "  # Détermination de l'intersection des boîtes englobantes\n",
        "  intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "  intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "  intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "  intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "  # Aire des boîtes englobantes prédites et réelles\n",
        "  true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "  pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "  # Aire de l'union des boîtes prédites et réelles\n",
        "  union_areas = pred_areas + true_areas - intersect_areas\n",
        "\n",
        "  iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "  return iou_scores\n",
        "\n",
        "def iou():\n",
        "  def iou_metrics(y_true, y_pred):\n",
        "    return compute_iou(y_true, y_pred)\n",
        "  iou_metrics.__name__= \"iou\"\n",
        "  return iou_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vidE3XHlAkst"
      },
      "source": [
        "Visualisation des données et labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yotZHKgAiV1"
      },
      "outputs": [],
      "source": [
        "# Si seuls x et y sont indiqués, on tire au hasard un numéro d'image et on affiche le label y associé  à l'image\n",
        "# Si un 2e y, nommé y_pred, est indiqué, alors les deux labels sont affichés côte à côte, afin de pouvoir les comparer\n",
        "# Enfin on peut également indiquer l'id de l'image que l'on souhaite visualiser.\n",
        "def print_data_localisation(x, y, y_pred=[], id=None, image_size=64):\n",
        "  if id==None:\n",
        "    # Tirage aléatoire d'une image dans la base\n",
        "    num_img = np.random.randint(x.shape[0]-1)\n",
        "  else:\n",
        "    num_img = id\n",
        "\n",
        "  img = x[num_img]\n",
        "  lab = y[num_img]\n",
        "\n",
        "  colors = [\"blue\", \"yellow\", \"red\", \"orange\", \"coral\", \"gold\", \"ivory\", \"fuchsia\", \"purple\", \"cyan\", \"navy\"] # Différentes couleurs pour les différentes classes\n",
        "  classes = ['MESCHA', 'VEREUR', 'ECUROU', 'PIEBAV', 'SITTOR', 'PINARB', 'MESNOI', 'MESNON', 'MESBLE', 'ROUGOR', 'ACCMOU']\n",
        "\n",
        "  if np.any(y_pred):\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "  # Affichage de l'image\n",
        "  plt.imshow(img)\n",
        "  # Détermination de la classe\n",
        "  class_id = np.argmax(lab[5:])\n",
        "\n",
        "  # Détermination des coordonnées de la boîte englobante dans le repère image\n",
        "  ax = (lab[1]*y_std[1] + y_mean[1]) * image_size\n",
        "  ay = (lab[2]*y_std[2] + y_mean[2]) * image_size\n",
        "  width = (lab[3]*y_std[3] + y_mean[3]) * image_size\n",
        "  height = (lab[4]*y_std[4] + y_mean[4]) * image_size\n",
        "  #print(\"x: {}, y: {}, w: {}, h:{}\".format(ax,ay,width, height))\n",
        "  # Détermination des extrema de la boîte englobante\n",
        "  p_x = [ax-width/2, ax+width/2]\n",
        "  p_y = [ay-height/2, ay+height/2]\n",
        "  # Affichage de la boîte englobante, dans la bonne couleur\n",
        "  plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "  plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "  plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "  plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id])\n",
        "  plt.title(\"Vérité Terrain : Image {} - {}\".format(num_img, classes[class_id]))\n",
        "\n",
        "  if np.any(y_pred):\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Affichage de l'image\n",
        "    plt.imshow(img)\n",
        "    lab = y_pred[num_img]\n",
        "    # Détermination de la classe\n",
        "    class_id = np.argmax(lab[5:])\n",
        "\n",
        "    # Détermination des coordonnées de la boîte englobante dans le repère image\n",
        "    ax = (lab[1]*y_std[1] + y_mean[1]) * image_size\n",
        "    ay = (lab[2]*y_std[2] + y_mean[2]) * image_size\n",
        "    width = (lab[3]*y_std[3] + y_mean[3]) * image_size\n",
        "    height = (lab[4]*y_std[4] + y_mean[4]) * image_size\n",
        "    #print(\"x: {}, y: {}, w: {}, h:{}\".format(ax,ay,width, height))\n",
        "    # Détermination des extrema de la boîte englobante\n",
        "    p_x = [ax-width/2, ax+width/2]\n",
        "    p_y = [ay-height/2, ay+height/2]\n",
        "    # Affichage de la boîte englobante, dans la bonne couleur\n",
        "    plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "    plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id])\n",
        "    plt.title(\"Prédiction : Image {} - {}\".format(num_img, classes[class_id]))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "for i in range(10):#x.shape[0]):\n",
        "    print_data_localisation(x_train, y_train, image_size=IMAGE_SIZE, id=i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE9_B3yuR4OH"
      },
      "source": [
        "Fonction d'affichage des courbes d'apprentissage et de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6O7R3qnCtlN"
      },
      "outputs": [],
      "source": [
        "def plot_training_analysis(history, metric='loss'):\n",
        "\n",
        "  loss = history.history[metric]\n",
        "  val_loss = history.history['val_' + metric]\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training ' + metric)\n",
        "  plt.plot(epochs, val_loss, 'g', label='Validation ' + metric)\n",
        "  plt.title('Training and validation ' + metric)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F_l_yNlDapa"
      },
      "source": [
        "## Travail à faire\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6D31NGPNyJp"
      },
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1YzCZe4pgnjJDVGklAaCHZ7HhlPJsadg9\" width=500></center>\n",
        "<caption><center> Figure 3: Illustration de l'architecture du réseau à construire.  </center></caption>\n",
        "\n",
        "Complétez les codes qui vous sont fournis pour obtenir un algorithme de localisation.\n",
        "Vous pouvez utiliser n'importe quelle base convolutive de votre choix (vous pouvez vous inspirer du TP sur les CNN que nous avons fait l'an passé), en revanche vous devrez porter une attention particulière à la couche de sortie.\n",
        "\n",
        "Vous allez en fait produire 3 sorties différentes : une caractérisant la présence d'un objet, une autre fournissant les coordonnées de la boîte englobante, et enfin une dernière effectuant la classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPOXiJ7hDcbr"
      },
      "outputs": [],
      "source": [
        "def create_model_localisation(input_shape=(64, 64, 3)):\n",
        "\n",
        "  input_layer = Input(shape=input_shape)\n",
        "\n",
        "  conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  ### A COMPLETER\n",
        "  ...\n",
        "  ...\n",
        "  # Cette couche vectorise le tenseur de sortie de votre base convolutive, et\n",
        "  # constituera l'entrée des 3 couches de sortie ci-dessous\n",
        "  prev_layer = Flatten()(..)\n",
        "\n",
        "  #### Couches de sortie A COMPLETER\n",
        "  output_p = Dense(..., activation=..., name='p')(prev_layer)   # Sortie caractérisant la présence d'un objet\n",
        "  output_coord = Dense(..., activation=..., name='coord')(prev_layer) # Sortie caractérisant les coordonnées de boîte englobante\n",
        "  output_class = Dense(..., activation=..., name='classes')(prev_layer) # Sortie caractérisant les probabilités de classe\n",
        "\n",
        "  output= [output_p, output_coord, output_class]\n",
        "  model = Model(input_layer, output)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYoVYfQpotjy"
      },
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1bnh8zU7Os-w-5TT8hV4xDoThKQc-Ywc2\" width=500></center>\n",
        "<caption><center> Figure 4: Illustration des fonctions de coût à utiliser pour l'entraînement. </center></caption>\n",
        "\n",
        "Pour entraîner votre réseau, vous allez donc devoir associer une fonction de coût à chacune des sorties du réseau. La fonction de coût totale sera la somme des trois fonctions de coût précédemment définies, pondérées par des poids définis dans la variable *loss_weights*.\n",
        "\n",
        "**Prenez le temps de tester différentes valeurs de *loss_weights* en fonction de l'évolution des métriques que vous observerez pendant l'entraînement.**\n",
        "\n",
        "Vous évaluerez vos résultats de manière qualitative (en affichant les boîtes englobantes prédites et réelles) mais aussi quantitatives grâce aux fonctions définies dans la section précédente. **N'hésitez pas à modifier un peu le paramètre iou_threshold positionné par défaut à 0.5** (une valeur de 0.4 vous permettra d'obtenir de meilleurs résultats !)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_ewlCn5Rovm"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "model = create_model_localisation()\n",
        "opt = Adam(learning_rate=3e-4)\n",
        "\n",
        "# Ici mettre, dans l'ordre, les fonctions de coût associées à chacune des sorties\n",
        "loss=[..., ..., ...]\n",
        "# On va associer une métrique à chaque sortie : l'accuracy pour les deux classifications,\n",
        "# et l'IoU définie plus tôt pour la qualité des boîtes englobantes.\n",
        "metrics=[ ['accuracy'], [iou()], ['accuracy']]\n",
        "loss_weights = [1, 1, 1]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics,\n",
        "              loss_weights=loss_weights\n",
        "              )\n",
        "history = model.fit(x_train, [y_train[:,0], y_train[:,1:5], y_train[:,5:]],\n",
        "              epochs=50,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val, [y_val[:,0], y_val[:,1:5], y_val[:,5:]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc-sGe8LNzA-"
      },
      "outputs": [],
      "source": [
        "# Analyse des résultats : courbes d'évolution de la fonction de perte, et de l'IoU des boîtes englobantes ainsi que de la précision des classes prédites\n",
        "plot_training_analysis(history, metric='loss')\n",
        "plot_training_analysis(history, metric='coord_iou')\n",
        "plot_training_analysis(history, metric='classes_accuracy')\n",
        "\n",
        "# Prédiction des données de test\n",
        "y_pred_presence, y_pred_coords, y_pred_classes = model.predict(x_test)\n",
        "y_pred = np.zeros(y_test.shape)\n",
        "for i in range(y_pred.shape[0]):\n",
        "  y_pred[i, 0] = y_pred_presence[i]\n",
        "  y_pred[i, 1:5] = y_pred_coords[i]\n",
        "  y_pred[i, 5:] = y_pred_classes[i]\n",
        "\n",
        "# Affichage des résultats sur plusieurs images\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=1, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=2, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=3, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=4, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=5, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=6, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=7, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=8, image_size=IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVU1bR_YEIMs"
      },
      "outputs": [],
      "source": [
        "class_res, accuracy = global_accuracy(y_test, y_pred)\n",
        "\n",
        "print(f\"La précision globale est de {accuracy:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"------------------------------------------\")\n",
        "print(\"| Classe | Précision | Rappel | F1-score |\")\n",
        "print(\"------------------------------------------\")\n",
        "for i in range(num_classes):\n",
        "  print(f\"| {class_labels[i]:7s}|   {class_res[i]['Precision']:.2f}    |  {class_res[i]['Rappel']:.2f}  |   {class_res[i]['F-score']:.2f}   |\")\n",
        "  print(\"------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiFO6fBns-OI"
      },
      "source": [
        "En pratique, il est délicat de trouver une bonne combinaison des fonctions de perte tel que vous l'avez fait sur les cellules précédentes. L'entropie croisée et l'erreur quadratique moyenne donnent des valeurs trop différentes pour être combinables efficacement.\n",
        "\n",
        "Une variante, peut-être plus simple à faire fonctionner, est d'utiliser uniquement l'erreur quadratique moyenne comme perte pour toutes les sorties. C'est cette variante qui est implémentée dans l'algorithme YOLO, dont nous implémenterons une version simplifiée dans la suite du TP.\n",
        "Testez cette solution ci-dessous. Comme sur l'exercice précédent, n'hésitez pas à faire varier le poids des différents éléments de la fonction de coût."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttGCeqz0Dc3y"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "model = create_model_localisation()\n",
        "opt = Adam(learning_rate=3e-4)\n",
        "\n",
        "loss = [..., ..., ...]\n",
        "metrics =[ ['accuracy'], [iou()], ['accuracy']]\n",
        "loss_weights = [...]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics,\n",
        "              loss_weights=loss_weights\n",
        "              )\n",
        "history = model.fit(x_train, [y_train[:,0], y_train[:,1:5], y_train[:,5:]],\n",
        "              epochs=50,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val, [y_val[:,0], y_val[:,1:5], y_val[:,5:]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKlN9-clJMrI"
      },
      "outputs": [],
      "source": [
        "# Analyse des résultats : courbes d'évolution de la fonction de perte, et de l'IoU des boîtes englobantes ainsi que de la précision des classes prédites\n",
        "plot_training_analysis(history, metric='loss')\n",
        "plot_training_analysis(history, metric='coord_iou')\n",
        "plot_training_analysis(history, metric='classes_accuracy')\n",
        "\n",
        "# Prédiction des données de test\n",
        "y_pred_presence, y_pred_coords, y_pred_classes = model.predict(x_test)\n",
        "y_pred = np.zeros(y_test.shape)\n",
        "for i in range(y_pred.shape[0]):\n",
        "  y_pred[i, 0] = y_pred_presence[i]\n",
        "  y_pred[i, 1:5] = y_pred_coords[i]\n",
        "  y_pred[i, 5:] = y_pred_classes[i]\n",
        "\n",
        "# Affichage des résultats sur plusieurs images\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=1, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=2, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=3, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=4, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=5, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=6, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=7, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=8, image_size=IMAGE_SIZE)\n",
        "\n",
        "\n",
        "class_res, accuracy = global_accuracy(y_test, y_pred, iou_thres=0.4)\n",
        "\n",
        "print(f\"La précision globale est de {accuracy:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"------------------------------------------\")\n",
        "print(\"| Classe | Précision | Rappel | F1-score |\")\n",
        "print(\"------------------------------------------\")\n",
        "for i in range(num_classes):\n",
        "  print(f\"| {class_labels[i]:7s}|   {class_res[i]['Precision']:.2f}    |  {class_res[i]['Rappel']:.2f}  |   {class_res[i]['F-score']:.2f}   |\")\n",
        "  print(\"------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRnqbdrzJx6Q"
      },
      "source": [
        "Compte-tenu de la taille réduite de la base de données, les résultats ne sont pas mal du tout ! On observe quelques confusions entre certaines classes mais les prédictions sont souvent intéressantes.\n",
        "\n",
        "**Fin de la séance 1**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQpmnmAt_bf"
      },
      "source": [
        "\n",
        "**Pour aller plus loin :**\n",
        "\n",
        "Il devrait cependant subsister un fort surapprentissage à ce stade. Comme nous l'avons vu en première année, vous avez plusieurs possibilités qui s'offrent à vous pour le corriger :\n",
        "\n",
        "*   Augmentation de la base de données. Vous pouvez pour cela vous appuyer sur le code fourni cu-dessous, avec une classe *Sequence* et l'utilisation de la librairie *Albumentation*.\n",
        "*   Utilisation de *transfer learning* : partant d'un réseau entraîné sur ImageNet (qui contient de nombreuses classes d'animaux), vous bénéficieriez de filtres très généraux qui aiderait à limiter le surapprentissage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dp1-obrdJgx"
      },
      "source": [
        "## Quelques bouts de code pour vous aider à aller un peu plus loin\n",
        "\n",
        "L'augmentation seule aide déjà un peu, mais le transfer learning accompagné d'augmentation de données donne les meilleurs résultats, avec presque 80% de bonnes détections !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jp6jwZidJgx"
      },
      "source": [
        "### Augmentation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5WuA43ZULxP"
      },
      "source": [
        "Le bloc de code suivant permet de définir des transformations colorimétriques à appliquer à notre base de données, de manière à augmenter artificiellement le nombre d'images de celles-ci :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS5wxAXvdJgx"
      },
      "outputs": [],
      "source": [
        "from albumentations import (Compose, RandomBrightnessContrast, RandomGamma, ShiftScaleRotate, RandomSizedBBoxSafeCrop)\n",
        "import albumentations as A\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "    RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=0.5)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sND_uaWPURfE"
      },
      "source": [
        "En première année, nous avons implémenté l'augmentation de données à l'aide d'un objet ImageDataGenerator. La limite de cette méthode est qu'elle ne peut s'appliquer que dans des cas où l'augmentation de données ne modifie pas le label associé à l'image. C'était le cas dans le TP de l'an passé sur les chiens et les chats : appliquer une rotation ou une translation à une image de chien (ou de chat) ne changeait rien au fait que l'image montrait un chien (ou un chat).\n",
        "\n",
        "Ici, il peut arriver que certaines transformations altèrent le label : une rotation appliquée à un objet en changera nécessairement les coordonnées de boîte englobante.\n",
        "Pour gérer cette difficulté, on va implémenter nous même le chargement des données, à l'aide d'un objet ```Sequence``` (défini ci-dessous).\n",
        "\n",
        "La méthode ```__get_item()__``` récupère les données et labels du prochain batch à fournir au modèle pour la descente de gradient. On peut ainsi, à la volée, appliquer l'augmentation de données sur les images et impacter la modification sur les labels associés (fonction ```apply_augmentation```)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9GXnEyYdJgy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class MangeoireSequence(Sequence):\n",
        "    # Initialisation de la séquence avec différents paramètres\n",
        "    def __init__(self, x_set, y_set, batch_size,augmentations):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.classes = ['MESCHA', 'VEREUR', 'ECUROU', 'PIEBAV', 'SITTOR', 'PINARB', 'MESNOI', 'MESNON', 'MESBLE', 'ROUGOR', 'ACCMOU']\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augmentations\n",
        "        self.indices1 = np.arange(x_set.shape[0])\n",
        "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
        "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
        "        # des batches au cours de l'entraînement\n",
        "\n",
        "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    # Il y a des problèmes d'arrondi dans les conversions de boîtes englobantes\n",
        "    # internes à la librairie Albumentations\n",
        "    # Pour les contourner, si les boîtes sont trop proches des bords, on les érode un peu\n",
        "    def erode_bounding_box(self, box):\n",
        "        epsilon = 0.01\n",
        "\n",
        "        xmin = max(box[0] - box[2]/2, epsilon)\n",
        "        ymin = max(box[1] - box[3]/2, epsilon)\n",
        "        xmax = min(box[0] + box[2]/2, 1-epsilon)\n",
        "        ymax = min(box[1] + box[3]/2, 1-epsilon)\n",
        "\n",
        "        cx = xmin + (xmax - xmin)/2\n",
        "        cy = ymin + (ymax - ymin)/2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        return np.array([cx, cy, width, height])\n",
        "\n",
        "    # Application de l'augmentation de données à chaque image du batch et aux\n",
        "    # boîtes englobantes associées\n",
        "    def apply_augmentation(self, bx, by):\n",
        "\n",
        "        batch_x = np.zeros((bx.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        batch_y = by\n",
        "\n",
        "        # Pour chaque image du batch\n",
        "        for i in range(len(bx)):\n",
        "            bboxes = []\n",
        "            box = by[i,1:5]\n",
        "            # Dénormalisation des coordonnées de boites englobantes\n",
        "            box[0] = (box[0]*y_std[1] + y_mean[1])\n",
        "            box[1] = (box[1]*y_std[2] + y_mean[2])\n",
        "            box[2] = (box[2]*y_std[3] + y_mean[3])\n",
        "            box[3] = (box[3]*y_std[4] + y_mean[4])\n",
        "            box = self.erode_bounding_box(box)\n",
        "            bboxes.append(box)\n",
        "\n",
        "            class_labels = []\n",
        "            class_id = np.argmax(by[i, 5:])\n",
        "            class_labels.append(self.classes[class_id])\n",
        "\n",
        "            img = bx[i]\n",
        "\n",
        "            # Application de l'augmentation à l'image et aux masques\n",
        "            transformed = self.augment(image=img.astype('float32'), bboxes=bboxes, class_labels=class_labels)\n",
        "            batch_x[i] = transformed['image']\n",
        "            batch_y_transformed = transformed['bboxes']\n",
        "\n",
        "            # Renormalisation des coordonnées de boîte englobante transformée\n",
        "            batch_y[i, 1] = (batch_y_transformed[0][0] - y_mean[1])/y_std[1]\n",
        "            batch_y[i, 2] = (batch_y_transformed[0][1] - y_mean[2])/y_std[2]\n",
        "            batch_y[i, 3] = (batch_y_transformed[0][2] - y_mean[3])/y_std[3]\n",
        "            batch_y[i, 4] = (batch_y_transformed[0][3] - y_mean[4])/y_std[4]\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
        "        batch_y = self.y[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
        "        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n",
        "\n",
        "        batch_y = np.array(batch_y)\n",
        "        return np.array(batch_x), (batch_y[:,0], batch_y[:,1:5].astype('float32'), batch_y[:,5:])\n",
        "\n",
        "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzUmu4j1MGHv"
      },
      "source": [
        "On peut ensuite instancier notre objet ```Sequence``` et afficher un exemple d'image augmentée avec le label associé."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUbm6gTMdJgy"
      },
      "outputs": [],
      "source": [
        "# Instanciation d'une Sequence\n",
        "train_gen = MangeoireSequence(x_train, y_train, 16, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Pour tester la séquence, nous sélectionnons les éléments du premier batch et les affichons\n",
        "batch_x, batch_y = train_gen.__getitem__(0)\n",
        "\n",
        "y_batch = np.zeros((batch_y[0].shape[0],1+4+num_classes))\n",
        "\n",
        "for i in range(batch_y[0].shape[0]):\n",
        "  y_batch[i, 0] = batch_y[0][i]\n",
        "  y_batch[i, 1:5] = batch_y[1][i]\n",
        "  y_batch[i, 5:] = batch_y[2][i]\n",
        "\n",
        "print_data_localisation(batch_x, y_batch, image_size=IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzTd5gw8MbYV"
      },
      "source": [
        "**Travail à faire** : lancez un nouvel apprentissage avec l'augmentation de données. Vous remplacerez, dans l'appel à la fonction ```fit```, les variables ```x_train``` et ```y_train``` par l'unique variable ```train_gen```.\n",
        "\n",
        "\n",
        "Vous devriez observer une nouvelle amélioration des résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFsr4WOPOMyy"
      },
      "source": [
        "### Transfert d'apprentissage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8hGj-vOQ2i"
      },
      "source": [
        "Nous avons vu en première année comment le transfert d'apprentissage pouvait également améliorer les résultats et limiter le sur-apprentissage. L'utilisation d'un réseau pré-entraîné permet souvent de mieux généraliser.\n",
        "\n",
        "Le bloc suivant permet de charger l'architecture du réseau VGG-16 :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LytjHH3lOyMh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False, # On ne conserve pas la partie Dense du réseau originel\n",
        "                  input_shape=(64, 64, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcMNz_yFOzP_"
      },
      "source": [
        "Une fois cette base convolutive chargée, vous pouvez créer un nouveau modèle en y adjoignant les couches de sortie que vous avez déjà créées lors de la séance précédente\n",
        "\n",
        "```\n",
        "input_layer = Input(shape=input_shape)\n",
        "vgg = conv_base(input_layer)\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9nQJfZIPdhT"
      },
      "source": [
        "**Travail à faire**\n",
        "\n",
        "Testez maintenant l'entraînement de ce réseau, en utilisant également l'augmentation de données. A vous de voir en fonction de vos premiers résultats quelle est la meilleure fonction de coût à utiliser.\n",
        "\n",
        "Vous devriez obtenir un résultats avoisinant les 80% de bonnes détections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKjt5haqbGi"
      },
      "source": [
        "# Détection d'objet : version simplifiée de YOLO\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1V4aAS7K_Akj83apuMZ2vRjNvjgdgoOCh\" width=500></center>\n",
        "<caption><center> Pipeline de l'algorithme YOLO ([Redmon 2016]) </center></caption>\n",
        "\n",
        "Dans cette partie, nous allons tenter d'aller un peu plus loin en considérant le problème plus complexe de la détection d'objet, c'est-à-dire de la localisation et la classification conjointe de tous les objets dans l'image ; pour cela nous allons implémenter une version simplifiée de YOLO. Cette version est considérée simplifiée car ne reprenant pas l'intégralité des éléments décrite dans l'article de Redmon (par exemple, sur le choix de l'optimiseur). Une des simplifications principales est également que nous ne considérerons **qu'un objet par cellule**.\n",
        "\n",
        "Pour rappel, l'idée de YOLO est de découper l'image en une grille de cellules et de réaliser une prédiction de plusieurs boîtes englobantes ainsi qu'une classification par cellule. La vidéo de la cellule suivante rappelle les concepts vus en cours sur YOLO et la détection d'objet en général.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Df-gdKaqlNb"
      },
      "source": [
        "Récupération des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP3pNNuKqdPD",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "git clone https://github.com/axelcarlier/wildlife.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laf92f_irz5S"
      },
      "source": [
        "## Fonctions utiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSZhLz_Pr26I"
      },
      "source": [
        "Définition des différentes variables utiles pour la suite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k3jBt13jqnF_"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 64 # Dimension des images en entrée du réseau\n",
        "CELL_PER_DIM = 8 # Nombre de cellules en largeur et en hauteur\n",
        "BOX_PER_CELL = 1 # Nombre d'objets par cellule\n",
        "NB_CLASSES = 4 # Nombre de classes du problème\n",
        "PIX_PER_CELL = round(IMAGE_SIZE/CELL_PER_DIM)\n",
        "\n",
        "CLASS_LABELS = ['buffalo', 'elephant', 'rhino', 'zebra']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnra6vWZr-6Y"
      },
      "source": [
        "### Chargement des données\n",
        "\n",
        "On charge les images dans la dimension demandée, dans un tenseur $x$. Pour les labels, on ne les structure pas directement dans le format YOLO, mais on les place dans une liste de liste de listes : la longueur de la liste parente est celle du nombre d'images de la base, celle de la liste intermédiaire est celle du nombre d'objets d'une image donnée, et enfin la liste de plus bas niveau a une longueur 5 et contiendra les coordonnées de boîte englobante et les labels de classe associés."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QMPqeqsrr7Sw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import glob, os, sys\n",
        "\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "    print(file)\n",
        "\n",
        "def load_data_detection(ds_path):\n",
        "\n",
        "  y_paths = []\n",
        "  # Détermination du nombre d'images total\n",
        "  for c in CLASS_LABELS:\n",
        "    path = ds_path + c + '/'\n",
        "    for file in os.listdir(path):\n",
        "      if file.endswith('.txt'):\n",
        "          y_paths.append(os.path.join(path, file))\n",
        "\n",
        "  dataset_size = len(y_paths)\n",
        "\n",
        "  # Préparation des structures de données pour x et y\n",
        "  x = np.zeros((dataset_size, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "  y = []\n",
        "\n",
        "  for i in range(len(y_paths)):\n",
        "    text_path = y_paths[i]\n",
        "    img_path = text_path[:-3] + 'jpg'\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "      img_path = text_path[:-3] + 'JPG'\n",
        "\n",
        "    # Lecture de l'image : on va remplir la variable x\n",
        "    # Lecture de l'image\n",
        "    img = Image.open(img_path)\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.Resampling.LANCZOS)\n",
        "    # Remplissage de la variable x\n",
        "    x[i] = np.asarray(img, dtype=np.int32)\n",
        "\n",
        "    # Texte : coordonnées de boîtes englobantes pour remplir y\n",
        "    boxes = []\n",
        "    # Texte : coordonnées de boîtes englobantes pour remplir y\n",
        "    text_file = open(text_path, \"r\")\n",
        "    # Récupération des lignes du fichier texte\n",
        "    rows = text_file.read().split('\\n')\n",
        "    # Parcours de chaque ligne\n",
        "    for row in rows:\n",
        "      if row != '':\n",
        "        # Séparation des différentes informations\n",
        "        row = list(row.split(' '))\n",
        "        box = []\n",
        "        # réorganisation : les 4 coordonnées de boîte englobantes (castées en flottants) d'abord\n",
        "        for r in row[1:]:\n",
        "          box.append(float(r))\n",
        "\n",
        "        box_normal = [box[0]-box[2]/2, box[1]-box[3]/2, box[0]+box[2]/2, box[1]+box[3]/2]\n",
        "\n",
        "        # Puis le label de classe (casté en entier) à la suite\n",
        "        box.append(int(row[0]))\n",
        "        boxes.append(box)\n",
        "\n",
        "    y.append(boxes)\n",
        "  return x, y\n",
        "\n",
        "# Chemin vers la base de données\n",
        "ds_path = \"./wildlife/\"\n",
        "x ,y = load_data_detection(ds_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-AM0YYZsJ4P"
      },
      "source": [
        "### Affichage des données\n",
        "\n",
        "Le code ci-dessous vous permettra d'afficher les images ainsi que leurs boîtes englobantes associées. On peut spécifier l'id d'une image en particulier ou, si l'on en spécifie pas, visualiser une image aléatoire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "h0J4gjOesMBM"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from scipy.special import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def print_data_detection(x, y, id=None, classes=CLASS_LABELS, image_size=IMAGE_SIZE):\n",
        "  if id==None:\n",
        "    # Tirage aléatoire d'une image dans la base\n",
        "    num_img = np.random.randint(x.shape[0])\n",
        "  else:\n",
        "    num_img = id\n",
        "\n",
        "  img = x[num_img]\n",
        "  if np.max(img) > 1:\n",
        "    img = img/255\n",
        "  boxes = y[num_img]\n",
        "\n",
        "  colors = [\"blue\", \"yellow\", \"red\", \"orange\"] # Différentes couleurs pour les différentes classes\n",
        "\n",
        "  # Affichage de l'image\n",
        "  plt.imshow(img)\n",
        "  for box in boxes:\n",
        "\n",
        "    # Détermination de la classe\n",
        "    class_id = box[4]\n",
        "\n",
        "    # Détermination des extrema de la boîte englobante\n",
        "    p_x = [(box[0]-box[2]/2) * IMAGE_SIZE, (box[0]+box[2]/2) * IMAGE_SIZE]\n",
        "    p_y = [(box[1]-box[3]/2) * IMAGE_SIZE, (box[1]+box[3]/2) * IMAGE_SIZE]\n",
        "\n",
        "    # Affichage de la boîte englobante, dans la bonne couleur\n",
        "    plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "    plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id], label=classes[class_id])\n",
        "    #plt.title(\"Vérité Terrain : Image {}\".format(num_img, classes[class_id]))\n",
        "\n",
        "  plt.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "print_data_detection(x, y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jirD7DirsRH2"
      },
      "source": [
        "### Écriture des labels au format YOLO\n",
        "\n",
        "Les deux fonctions ci-dessous sont essentielles car elles permettent de convertir les boîtes englobantes dans le format adopté par YOLO (voir la section Modèle un peu plus bas), mais également de faire l'opération inverse afin d'interpréter la sortie du réseau.\n",
        "\n",
        "Notez que la fonction *get_box_from_yolo* intègre dans les boîtes englobantes une information supplémentaire par rapport aux données chargées initialement : la probabilité de présence associée à la boîte englobante.\n",
        "\n",
        "**Travail à faire**\n",
        "-   Lisez attentivement la fonction ```set_box_for_yolo``` afin de bien comprendre comment les boîtes englobantes sont rangées dans le tenseur YOLO\n",
        "-   Écrivez la fonction ```get_box_from_yolo``` pour lire les informations dans le tenseur YOLO et créer la liste boîtes englobantes associées."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "aUnk8T3MsWv6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.231132, 0.631387, 0.292453, 0.270073, 0], [0.75, 0.532847, 0.141509, 0.262774, 0], [0.563679, 0.554745, 0.240566, 0.277372, 0], [0.509434, 0.434307, 0.273585, 0.167883, 0]], [[0.646484, 0.656081, 0.697656, 0.666216, 0]]]\n",
            "[[[0.231132, 0.631387, 0.292453, 0.270073, 1.0], [0.509434, 0.434307, 0.273585, 0.167883, 1.0], [0.563679, 0.554745, 0.240566, 0.277372, 1.0], [0.75, 0.532847, 0.141509, 0.262774, 1.0]], [[0.646484, 0.656081, 0.697656, 0.666216, 1.0]]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from scipy.special import expit, softmax\n",
        "\n",
        "\n",
        "# Ecrit la liste de boîtes englobantes dans le tenseur YOLO\n",
        "def set_box_for_yolo(y, num_classes=NB_CLASSES, image_size=IMAGE_SIZE, cell_size=PIX_PER_CELL):\n",
        "  nb_cells_per_dim = round(image_size/cell_size)\n",
        "\n",
        "  y_YOLO = np.zeros((len(y), nb_cells_per_dim, nb_cells_per_dim, 1 + 4 + num_classes))\n",
        "\n",
        "  for i in range(len(y)):\n",
        "    for box in y[i]:\n",
        "      # Coordonnées du centre de la boîte englobante dans le repère image\n",
        "      cx, cy = box[0] * image_size, box[1] * image_size\n",
        "      # Détermination des indices de la cellule dans laquelle tombe le centre\n",
        "      ind_x, ind_y = int(cx // cell_size), int(cy // cell_size)\n",
        "      # YOLO : \"The (x, y) coordinates represent the center of the box relative to the bounds of the grid cell.\"\n",
        "      # On va donc calculer les coordonnées du centre relativement à la cellule dans laquelle il se situe\n",
        "      y_YOLO[i, ind_x, ind_y, 1] = (cx - ind_x * cell_size) / cell_size\n",
        "      y_YOLO[i, ind_x, ind_y, 2] = (cy - ind_y * cell_size) / cell_size\n",
        "      # Largeur et hauteur de boîte\n",
        "      y_YOLO[i, ind_x, ind_y, 3] = box[2]\n",
        "      y_YOLO[i, ind_x, ind_y, 4] = box[3]\n",
        "\n",
        "      # Indice de confiance de la boîte englobante pour la cellule correspondante\n",
        "      y_YOLO[i, ind_x, ind_y, 0] = 1\n",
        "      # On range les probabilités de classe à la fin du vecteur ([ Présence ; cx ; cy ; w ; h ; CLASSES])\n",
        "      y_YOLO[i, ind_x, ind_y, 5:] = to_categorical(box[4], num_classes=num_classes)\n",
        "\n",
        "  return y_YOLO\n",
        "\n",
        "# Renvoit une liste de boîtes englobantes à partir d'un tenseur YOLO.\n",
        "# Si mode = 'pred', il s'agit d'une prédiction du réseau, il faut alors utiliser la fonction sigmoide\n",
        "# pour obtenir la présence prédite, et la fonction softmax pour obtenir les probabilités de classe\n",
        "# Dans tous les cas, on renvoit uniquement les boîtes englobantes donc l'indice de confiance excède\n",
        "# le seuil confidence_threshold\n",
        "def get_box_from_yolo(y_YOLO, mode=None, confidence_threshold=0.5, num_classes=NB_CLASSES, image_size=IMAGE_SIZE, cell_size=PIX_PER_CELL):\n",
        "  nb_cells_per_dim = round(image_size/cell_size)\n",
        "  y = np.zeros(len(y_YOLO)).tolist()\n",
        "\n",
        "  for i in range(len(y_YOLO)):\n",
        "    y[i] = []\n",
        "    obj = 0\n",
        "    for i_x in range(nb_cells_per_dim) :\n",
        "      for i_y in range(nb_cells_per_dim) :\n",
        "        \n",
        "        p = (tf.math.sigmoid(y_YOLO[i, i_x, i_y, 0]) if mode == \"pred\" else y_YOLO[i, i_x, i_y, 0])\n",
        "\n",
        "        if p > (confidence_threshold if mode == \"pred\" else 0) :\n",
        "          cxr = y_YOLO[i, i_x, i_y, 1]\n",
        "          cyr = y_YOLO[i, i_x, i_y, 2]\n",
        "\n",
        "          box = [0,0,0,0,0]\n",
        "\n",
        "          box[0] = float(((cxr * cell_size) + (i_x * cell_size)) / image_size)\n",
        "          box[1] = float(((cyr * cell_size) + (i_y * cell_size)) / image_size)\n",
        "          box[2] = float(y_YOLO[i, i_x, i_y, 3])\n",
        "          box[3] = float(y_YOLO[i, i_x, i_y, 4])\n",
        "          box[4] = float(p)\n",
        "          y[i].append(box)\n",
        "        # else :\n",
        "        #   pass\n",
        "        \n",
        "  \n",
        "  return y\n",
        "# On s'assure de pouvoir passer d'une représentation à l'autre sans altérer les données\n",
        "print(y[:2])\n",
        "print(get_box_from_yolo(set_box_for_yolo(y[:2])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoB-v0XgUWae"
      },
      "source": [
        "**Résultat attendu**\n",
        "```\n",
        "[[[0.483984, 0.522973, 0.749219, 0.645946, 0]], [[0.509375, 0.649324, 0.80625, 0.595946, 0]]]\n",
        "[[[0.483984, 0.522973, 0.749219, 0.645946, 0, 1.0]], [[0.509375, 0.649324, 0.80625, 0.595946, 0, 1.0]]]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrtoRD8bVjbU"
      },
      "source": [
        "**Fin de la séance 2**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hXjZ_ybshkx"
      },
      "source": [
        "### Augmentation de données\n",
        "\n",
        "Dans la cellule ci-dessous, il vous faudra intégrer les augmentations que vous aurez choisi. **Attention, ne faites cette partie que dans un second temps, lorsque vous aurez une première version du réseau qui fonctionnera !**\n",
        "\n",
        "Aidez-vous de [cette page](https://albumentations.ai/docs/getting_started/transforms_and_targets/) pour déterminer des augmentations qui peuvent fonctionner."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83emcM2ysfoN"
      },
      "outputs": [],
      "source": [
        "from albumentations import (Compose, ShiftScaleRotate, HorizontalFlip)\n",
        "import albumentations as A\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    #### A COMPLETER, MAIS SEULEMENT LORSQUE VOUS AVEZ UN RESEAU QUI (SUR-)APPREND !\n",
        "    # HorizontalFlip(p=0.5),\n",
        "    # ...\n",
        "], bbox_params=A.BboxParams(format='yolo'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOY1ljkJsqPc"
      },
      "source": [
        "L'objet ```Sequence``` défini ci-dessous nous permettra la mise en batch de nos données. Il est très similaire à celui de la localisation d'objet mais il utilise les fonctions ```set_box_for_yolo``` et ```get_box_from_yolo```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88vbS9NzsoJN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class YOLOSequence(Sequence):\n",
        "    # Initialisation de la séquence avec différents paramètres\n",
        "    def __init__(self, x_set, y_set, batch_size,augmentations):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augmentations\n",
        "        self.indices1 = np.arange(x_set.shape[0], dtype='int')\n",
        "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
        "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
        "        # des batches au cours de l'entraînement\n",
        "\n",
        "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "\n",
        "    # Il y a des problèmes d'arrondi dans les conversions de boîtes englobantes\n",
        "    # internes à la librairie Albumentations\n",
        "    # Pour les contourner, si les boîtes sont trop proches des bords, on les érode un peu\n",
        "    def erode_bounding_box(self, box, epsilon = 0.02):\n",
        "        eroded_box = []\n",
        "\n",
        "        xmin = max(box[0] - box[2]/2, epsilon)\n",
        "        ymin = max(box[1] - box[3]/2, epsilon)\n",
        "        xmax = min(box[0] + box[2]/2, 1-epsilon)\n",
        "        ymax = min(box[1] + box[3]/2, 1-epsilon)\n",
        "\n",
        "        cx = xmin + (xmax - xmin)/2\n",
        "        cy = ymin + (ymax - ymin)/2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        eroded_box = [cx, cy, width, height, box[4]]\n",
        "        return eroded_box\n",
        "\n",
        "    # Application de l'augmentation de données à chaque image du batch et aux\n",
        "    # boîtes englobantes associées\n",
        "    def apply_augmentation(self, bx, by):\n",
        "\n",
        "        batch_x = np.zeros((bx.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        batch_y = []\n",
        "\n",
        "        # Pour chaque image du batch\n",
        "        for i in range(len(bx)):\n",
        "            boxes = []\n",
        "            # Erosion des boîtes englobantes\n",
        "            for box in by[i]:\n",
        "              boxes.append(self.erode_bounding_box(box))\n",
        "\n",
        "            # Application de l'augmentation à l'image et aux boîtes englobantes\n",
        "            transformed = self.augment(image=bx[i].astype('float32'), bboxes=boxes)\n",
        "            batch_x[i] = transformed['image']\n",
        "            batch_y_transformed = transformed['bboxes']\n",
        "            batch_y.append(batch_y_transformed)\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
        "    def __getitem__(self, idx):\n",
        "        # Sélection des indices des données du prochain batch\n",
        "        batch_indices = self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        # Récupération des données puis des labels du batch\n",
        "        batch_x = self.x[batch_indices]\n",
        "        batch_boxes = [self.y[item] for item in list(batch_indices)]\n",
        "        # Application de l'augmentation de données\n",
        "        batch_x_aug, batch_boxes_aug = self.apply_augmentation(batch_x, batch_boxes)\n",
        "\n",
        "        # Préparation des données pour le réseau :\n",
        "        # Normalisation des entrées\n",
        "        batch_x_aug = batch_x_aug/255\n",
        "        # Passage des sorties au format YOLO\n",
        "        batch_y_YOLO = set_box_for_yolo(batch_boxes_aug)\n",
        "\n",
        "        return np.array(batch_x_aug), batch_y_YOLO\n",
        "\n",
        "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K3TjW8osu23"
      },
      "outputs": [],
      "source": [
        "# Instanciation d'une Sequence\n",
        "train_gen = YOLOSequence(x[:1], y[:1], 1, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Pour tester la séquence, nous sélectionnons les éléments du premier batch et les affichons\n",
        "batch_x, batch_y = train_gen.__getitem__(0)\n",
        "\n",
        "print_data_detection(batch_x, get_box_from_yolo(batch_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8jLZH-ss7Gq"
      },
      "source": [
        "## Implémentation de YOLO\n",
        "\n",
        "### Modèle\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1_wXc_gTIAr37STaxu3chq1EEjVSKv6a5\" width=500></center>\n",
        "<caption><center> Illustration de la couche de sortie de YOLO. </center></caption>\n",
        "\n",
        "Le modèle que je vous propose ci-dessous n'est qu'une possibilité parmi beaucoup d'autres.\n",
        "A vous de compléter la dernière couche pour avoir une sortie de la bonne dimension.\n",
        "\n",
        "**Remarque importante** : comme le tenseur de sortie de YOLO est un peu complexe à manipuler, on choisit ici de regrouper l'ensemble des prédictions dans une seule et même sortie, ce qui nous oblige à utiliser la même fonction d'activation pour toutes nos sorties. On utilisera donc l'activation **linéaire** pour toutes ces sorties. On appliquera les fonctions sigmoïde et softmax pour les sorties \"présence\" et \"probablités de classe\" directement dans la fonction de coût !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VvgG-yHDsxyk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Reshape, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "def create_model_YOLO(input_shape=(64, 64, 3)):\n",
        "  input_layer = Input(shape=input_shape)\n",
        "\n",
        "  conv1 = Conv2D(32, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(input_layer)\n",
        "  conv1 = Conv2D(32, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  conv2 = Conv2D(64, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  conv3 = Conv2D(128, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(1024, 3, activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "\n",
        "  output = Conv2D(1, NB_CLASSES + 5,activation = 'elu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "\n",
        "  model = Model(input_layer, output)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "OUoxSzHDtChh"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,672</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,945</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m1,180,672\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │        \u001b[38;5;34m82,945\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,550,625</span> (5.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,550,625\u001b[0m (5.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,550,625</span> (5.92 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,550,625\u001b[0m (5.92 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = create_model_YOLO()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd94rYW2tIZu"
      },
      "source": [
        "### Fonction de coût\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1Fbt_Wh_BqZj8Pwt3-04325ItCkQp5G9X\" style=\"width:500;height:300px;\"></center>\n",
        "<caption><center> Détail de la fonction de perte définie dans l'article YOLO v1 </center></caption>\n",
        "\n",
        "Nous arrivons maintenant à la partie délicate de l'implémentation de YOLO : la définition de la fonction de coût à utiliser. En effet cette fonction de coût, qui sera appelée pendant l'entraînement, traitera des tenseurs et non des tableau *numpy*. On doit donc utiliser la librairie Tensorflow qui permet de manipuler les tenseurs. Les fonctions dont vous aurez besoin sont décrites majoritairement sur [cette page](https://www.tensorflow.org/api_docs/python/tf/math), ainsi qu'[ici](https://www.tensorflow.org/api_docs/python/tf/nn).\n",
        "\n",
        "Une partie essentielle de la fonction est déjà écrite (fonction YOLO_loss) : celle qui permet de séparer les données des cellules dites \"vide\" (la vérité terrain ne contient pas de boîte englobante) des \"non vides\". Cette fonction est apelée en première, et fait appel aux 3 sous-fonctions box_loss, coord_loss, et nobox_loss que vous devez compléter.\n",
        "\n",
        "Le détail de la fonction de coût est indiqué ci-dessus : dans l'article $\\lambda_{\\text{coord}} = 5$ et $\\lambda_{\\text{noobj}} = 0.5$. Les $x_i$, $y_i$, $w_i$, $h_i$ correspondent aux coordonnées d'une boîte englobante, $C_i$ correspond à la probabilité de présence d'un objet dans la cellule, et les $p_i(c)$ sont les probabilités de classe.\n",
        "\n",
        "A vous de compléter l'expression des sous-fonctions de la fonction de coût. **N'oubliez pas d'appliquer une sigmoïde aux présences ($C_i$) et une softmax aux probabilités de classe $p_i$) !!**\n",
        "\n",
        "**NB : cette implémentation de la fonction de coût est très simplifiée et prend en compte le fait qu'il n'y a qu'une seule boîte englobante par cellule.**\n",
        "\n",
        "**NB 2: la fonction tf.math.sqrt peut retourner NaN si elle est appelée sur une entrée négative. Un fix qui fonctionne est d'écrire tf.math.sqrt(tf.maximum(x, 1e-9)) pour qu'elle retourne une valeur proche de 0 plutôt que NaN.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O82KwmA5iEW"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "### A COMPLETER\n",
        "# Définition de la fonction de perte YOLO\n",
        "def YOLOss(lambda_coord, lambda_noobj, batch_size):\n",
        "\n",
        "    # Partie \"verte\" : sous-partie concernant l'indice de confiance et les\n",
        "    # probabilités de classe dans le cas où une boîte est présente dans la cellule\n",
        "    def box_loss(y_true, y_pred):\n",
        "      for i in range(8**2):\n",
        "        for c in range(NB_CLASSES) :\n",
        "          pass\n",
        "      return\n",
        "\n",
        "    # Partie \"bleue\" : sous-partie concernant les coordonnées de boîte englobante\n",
        "    # dans le cas où une boîte est présente dans la cellule\n",
        "    def coord_loss(y_true, y_pred):\n",
        "\n",
        "      def ddd(x1,x2,y1,y2):\n",
        "        return ((x1 - x2)**2 + (y1 - y2)**2)**2\n",
        "\n",
        "      f = 0.0\n",
        "      for i in range(8**2):\n",
        "        for j in range(batch_size):\n",
        "          f += ddd(y_true[i][j][0],y_pred[i][j][0],y_true[i][j][1],y_pred[i][j][1])\n",
        "      for i in range(8**2):\n",
        "        for j in range(batch_size):\n",
        "          f += ddd(y_true[i][j][0],y_pred[i][j][0],y_true[i][j][1],y_pred[i][j][1])\n",
        "      return f\n",
        "\n",
        "\n",
        "    # Partie \"rouge\" : sous-partie concernant l'indice de confiance\n",
        "    # dans le cas où aucune boîte n'est présente dans la cellule\n",
        "    def nobox_loss(y_true, y_pred):\n",
        "      s1 = 0.0\n",
        "      for i in range(8**2):\n",
        "        s2 = 0\n",
        "        for j in range(batch_size):\n",
        "          s2 += (y_true[i][j][4] - y_pred[i][j][4])**2\n",
        "        s1 += s2\n",
        "      return s1\n",
        "\n",
        "\n",
        "    def YOLO_loss(y_true, y_pred):\n",
        "\n",
        "      # On commence par reshape les tenseurs de bs x S x S x (5B+C) à (bsxSxS) x (5B+C)\n",
        "      y_true = tf.reshape(y_true, [-1, 9])\n",
        "      y_pred = tf.reshape(y_pred, [-1, 9])\n",
        "\n",
        "      # On cherche (dans les labels y_true) les indices des cellules pour lesquelles au moins la première boîte englobante est présente\n",
        "      not_empty = tf.math.greater_equal(y_true[:, 0], tf.constant([1.0]))\n",
        "      indices = tf.range(tf.shape(y_true)[0])\n",
        "      indices_notempty_cells = indices[not_empty]\n",
        "\n",
        "      empty = tf.math.less_equal(y_true[:, 0], tf.constant([0.0]))\n",
        "      indices_empty_cells = indices[empty]\n",
        "\n",
        "      # On sépare les cellules de y_true et y_pred avec ou sans boîte englobante\n",
        "      y_true_notempty = tf.gather(y_true, indices_notempty_cells)\n",
        "      y_pred_notempty = tf.gather(y_pred, indices_notempty_cells)\n",
        "\n",
        "      y_true_empty = tf.gather(y_true, indices_empty_cells)\n",
        "      y_pred_empty = tf.gather(y_pred, indices_empty_cells)\n",
        "\n",
        "\n",
        "      return (box_loss(y_true_notempty, y_pred_notempty) + lambda_coord*coord_loss(y_true_notempty, y_pred_notempty) + lambda_noobj*nobox_loss(y_true_empty, y_pred_empty))/batch_size\n",
        "\n",
        "\n",
        "    # Return a function\n",
        "    return YOLO_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eAP6WKLto_b"
      },
      "source": [
        "### Apprentissage\n",
        "\n",
        "Comme d'habitude, on sépare nos données en plusieurs ensembles (ici apprentissage et validation suffiront)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAVR5EPGtUlo"
      },
      "outputs": [],
      "source": [
        "# Séparation des données en ensemble de validation et d'apprentissage\n",
        "indices = np.arange(x.shape[0], dtype='int')\n",
        "np.random.seed(1)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train = x[indices[:1355]]\n",
        "y_train = [y[i] for i in indices[:1355]]\n",
        "\n",
        "x_val = x[indices[1355:]]\n",
        "y_val = [y[i] for i in indices[1355:]]\n",
        "\n",
        "y_val_YOLO = set_box_for_yolo(y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E9nT-cxtvT2"
      },
      "source": [
        "Prenez le temps de tester votre modèle et votre fonction de coût, ainsi que vos réglages d'hyperparamètres, en sur-apprenant sur une image d'abord, puis sur un batch d'images. Entraînez votre réseau et visualisez ses prédictions sur les données d'entraînement, puis de validation, pour obtenir une intuition sur les valeurs de *loss* permettant d'obtenir des résultats \"acceptables\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0anQ56HrttMr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size=16\n",
        "model = create_model_YOLO()\n",
        "opt = Adam(learning_rate=3e-4) # NB : n'hésitez pas à tester d'autres valeurs de learning rate\n",
        "\n",
        "train_gen = YOLOSequence(x_train, y_train, batch_size, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Comme l'entraînement est instable, on déclenche une sauvegarde du modèle à chaque fois que\n",
        "# la perte de validation atteint un nouveau minimum\n",
        "model_saver = ModelCheckpoint('tmp/best_weights', monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
        "\n",
        "loss=[YOLOss(5, 0.5, batch_size)]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt)\n",
        "\n",
        "history = model.fit(train_gen,\n",
        "              epochs=150,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val/255, y_val_YOLO),\n",
        "              callbacks = [model_saver])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyCNRDtxu3eC"
      },
      "source": [
        "### Test et affichage des résultats\n",
        "\n",
        "#### Test de la version à l'issue de l'entraînement\n",
        "\n",
        "**Sur l'ensemble d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChmIEq9SvBeH"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_train/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.3, mode='pred')\n",
        "print_data_detection(x_train, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPqwEGLAvGYx"
      },
      "outputs": [],
      "source": [
        "print_data_detection(x_train, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_rcK_9uvODw"
      },
      "source": [
        "**Sur l'ensemble de validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKK_L5k_vGwH"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_val/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.5, mode='pred')\n",
        "print_data_detection(x_val, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOClF65EvKUI"
      },
      "outputs": [],
      "source": [
        "print_data_detection(x_val, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2Gv1HJw5Fjv"
      },
      "source": [
        "#### Test de la meilleure version sauvegardée\n",
        "\n",
        "La cellule ci-dessous vous permettra de charger les poids sauvegardés lorsque la meilleur performance a été atteinte sur l'ensemble de validation pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3SizeuJ5Ild"
      },
      "outputs": [],
      "source": [
        "model.load_weights('tmp/best_weights')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IpuvyWd5LCl"
      },
      "source": [
        "**Sur l'ensemble d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnkM9FJi5Pvx"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_train/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.3, mode='pred')\n",
        "print_data_detection(x_train, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1IZ5ETF5RUc"
      },
      "outputs": [],
      "source": [
        "print_data_detection(x_train, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua8OpNLs5W06"
      },
      "source": [
        "**Sur l'ensemble de validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As1bbe2g5TDF"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_val/255)\n",
        "y_pred_YOLO = get_box_from_yolo(y_pred, confidence_threshold=0.3, mode='pred')\n",
        "print_data_detection(x_val, y_pred_YOLO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHzzeaLF5axn"
      },
      "outputs": [],
      "source": [
        "print_data_detection(x_val, y_pred_YOLO)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
